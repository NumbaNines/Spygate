#!/usr/bin/env python3
"""
SMART INTERVALS: Multi-Frequency Burst Sampling
==============================================
Smart burst sampling with different intervals for different elements:
- Clocks + Down/Distance: Every 10 seconds (3 frames)
- Scores: Every 30 seconds (1 frame)
Target: 90-second video in 8-12 seconds with maximum efficiency.
"""

import os
import random
import sys
import time
from collections import Counter
from pathlib import Path

import cv2
import numpy as np

# Add src to path
sys.path.append("src")

from spygate.ml.enhanced_game_analyzer import EnhancedGameAnalyzer


class SmartIntervalAnalyzer:
    """Smart multi-interval burst sampling analyzer."""

    def __init__(self):
        """Initialize with smart interval optimizations."""
        print("üß† Initializing SMART INTERVAL analyzer...")

        # Initialize base analyzer
        self.analyzer = EnhancedGameAnalyzer()

        # Smart interval configuration
        self.frequent_interval = 10.0  # Clocks + down/distance every 10s
        self.rare_interval = 30.0  # Scores every 30s
        self.burst_frames = 3  # 3 frames for frequent elements
        self.rare_frames = 1  # 1 frame for rare elements
        self.burst_window = 2.0  # Check frames in last 2s before decision

        # Element categories (matching temporal manager names)
        self.frequent_elements = ["game_clock", "play_clock", "down_distance"]
        self.rare_elements = ["scores"]

        # Target classes (no generic "hud")
        self.target_classes = [
            "possession_triangle_area",
            "territory_triangle_area",
            "preplay_indicator",
            "play_call_screen",
            "down_distance_area",
            "game_clock_area",
            "play_clock_area",
        ]

        # Ultra-low resolution for speed
        self.target_resolution = 480

        # Decision tracking
        self.last_decisions = {}
        self.decision_history = []

        print(
            f"‚úÖ Frequent elements: {self.frequent_elements} (every {self.frequent_interval}s, {self.burst_frames} frames)"
        )
        print(
            f"‚úÖ Rare elements: {self.rare_elements} (every {self.rare_interval}s, {self.rare_frames} frame)"
        )
        print(f"‚úÖ Using {len(self.target_classes)} specific classes (no generic hud)")
        print("‚úÖ SMART INTERVAL optimizations initialized")

    def calculate_smart_frames(self, video_duration: float, fps: float) -> dict:
        """Calculate which frames to analyze using smart interval sampling."""

        # Calculate frequent decision points (every 10 seconds)
        frequent_times = []
        current_time = self.frequent_interval
        while current_time <= video_duration:
            frequent_times.append(current_time)
            current_time += self.frequent_interval

        # Calculate rare decision points (every 30 seconds)
        rare_times = []
        current_time = self.rare_interval
        while current_time <= video_duration:
            rare_times.append(current_time)
            current_time += self.rare_interval

        print(f"üìä Frequent decisions: {len(frequent_times)} (every {self.frequent_interval}s)")
        print(f"üìä Rare decisions: {len(rare_times)} (every {self.rare_interval}s)")

        all_frames = []

        # Add frequent element frames (3 frames per decision)
        for decision_time in frequent_times:
            frame_times = [
                decision_time - 2.0,  # 2 seconds before
                decision_time - 1.0,  # 1 second before
                decision_time - 0.0,  # At decision point
            ]

            for frame_time in frame_times:
                if frame_time >= 0:
                    frame_num = int(frame_time * fps)
                    all_frames.append(
                        {
                            "frame_num": frame_num,
                            "time": frame_time,
                            "decision_point": decision_time,
                            "type": "frequent",
                            "elements": self.frequent_elements,
                        }
                    )

        # Add rare element frames (1 frame per decision)
        for decision_time in rare_times:
            frame_time = decision_time  # Just at decision point
            frame_num = int(frame_time * fps)
            all_frames.append(
                {
                    "frame_num": frame_num,
                    "time": frame_time,
                    "decision_point": decision_time,
                    "type": "rare",
                    "elements": self.rare_elements,
                }
            )

        # Sort by frame number and remove duplicates
        all_frames.sort(key=lambda x: x["frame_num"])

        # Merge frames that are at the same time
        merged_frames = []
        current_frame = None

        for frame in all_frames:
            if current_frame is None:
                current_frame = frame
            elif current_frame["frame_num"] == frame["frame_num"]:
                # Merge elements
                current_frame["elements"] = list(set(current_frame["elements"] + frame["elements"]))
                current_frame["type"] = "combined"
            else:
                merged_frames.append(current_frame)
                current_frame = frame

        if current_frame:
            merged_frames.append(current_frame)

        print(f"üìä Total frames: {len(merged_frames)} (after merging duplicates)")

        # Group by decision points for easier processing
        decision_groups = {}
        for frame in merged_frames:
            decision_point = frame["decision_point"]
            if decision_point not in decision_groups:
                decision_groups[decision_point] = []
            decision_groups[decision_point].append(frame)

        return {
            "frames": merged_frames,
            "decision_groups": decision_groups,
            "frequent_decisions": len(frequent_times),
            "rare_decisions": len(rare_times),
        }

    def preprocess_frame_fast(self, frame: np.ndarray) -> np.ndarray:
        """Fast frame preprocessing for smart interval analysis."""
        height, width = frame.shape[:2]

        # Aggressive resizing for speed
        if width > self.target_resolution:
            scale = self.target_resolution / width
            new_width = int(width * scale)
            new_height = int(height * scale)
            frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_LINEAR)

        return frame

    def analyze_frame_smart(
        self, frame: np.ndarray, current_time: float, target_elements: list
    ) -> dict:
        """Analyze single frame for specific elements only."""

        # Preprocess frame
        frame = self.preprocess_frame_fast(frame)

        # Analyze with base analyzer
        results = self.analyzer.analyze_frame(frame, current_time)

        # DEBUG: Check what YOLO detected
        if hasattr(self.analyzer, "model") and hasattr(self.analyzer.model, "last_detections"):
            detections = self.analyzer.model.last_detections
            if detections:
                detected_classes = [d.get("class", "unknown") for d in detections]
                print(f"üîç Frame {current_time:.1f}s detected: {detected_classes}")
            else:
                print(f"üîç Frame {current_time:.1f}s: No detections")

        # Extract only target values for efficiency
        temporal_mgr = self.analyzer.temporal_manager
        extracted_values = {}

        for element_type in target_elements:
            try:
                value = temporal_mgr.get_current_value(element_type)
                extracted_values[element_type] = value
            except:
                extracted_values[element_type] = "Unknown"

        return {
            "results": results,
            "values": extracted_values,
            "time": current_time,
            "target_elements": target_elements,
        }

    def vote_on_smart_results(self, burst_results: list, element_type: str) -> dict:
        """Perform consensus voting on specific element type."""
        if not burst_results:
            return {"winner": "Unknown", "confidence": 0.0, "votes": 0, "total": 0}

        # Collect values for this element
        values = []
        for result in burst_results:
            if element_type in result["values"] and result["values"][element_type] != "Unknown":
                values.append(result["values"][element_type])

        if values:
            # Count votes
            vote_counts = Counter(values)
            winner, count = vote_counts.most_common(1)[0]
            confidence = count / len(burst_results)

            return {
                "winner": winner,
                "confidence": confidence,
                "votes": count,
                "total": len(burst_results),
                "all_votes": dict(vote_counts),
            }
        else:
            return {
                "winner": "Unknown",
                "confidence": 0.0,
                "votes": 0,
                "total": len(burst_results),
                "all_votes": {},
            }


def test_temporal_SMART_INTERVALS():
    """Test smart multi-interval burst sampling."""
    print("üß† SMART INTERVALS: Multi-Frequency Burst Sampling")
    print("=" * 80)
    print("üöÄ SMART INTERVAL STRATEGY:")
    print("   ‚úÖ Clocks + Down/Distance: Every 10s (3 frames)")
    print("   ‚úÖ Scores: Every 30s (1 frame)")
    print("   ‚úÖ Selective OCR per frame type")
    print("   ‚úÖ Ultra-low resolution (480p)")
    print('   ‚úÖ No generic "hud" class')
    print("   ‚úÖ Maximum efficiency optimization")
    print("=" * 80)

    # Initialize smart analyzer
    smart_analyzer = SmartIntervalAnalyzer()

    # Load test video
    video_path = "1 min 30 test clip.mp4"
    if not os.path.exists(video_path):
        print(f"‚ùå Video not found: {video_path}")
        return

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"‚ùå Could not open video: {video_path}")
        return

    # Get video info
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = total_frames / fps

    print(f"üìπ Video: {video_path} ({duration:.1f}s, {total_frames} frames)")

    # Calculate smart frames
    smart_data = smart_analyzer.calculate_smart_frames(duration, fps)
    frames_to_process = smart_data["frames"]
    decision_groups = smart_data["decision_groups"]

    print(f"üß† SMART MODE: Processing {len(frames_to_process)} frames total")
    print(f"üéØ Target: 8-12 seconds processing time")

    # Create output directory
    output_dir = Path("temporal_test_results_smart")
    output_dir.mkdir(exist_ok=True)

    print("\nüß† SMART ANALYSIS: Multi-frequency sampling with selective OCR...")
    print("=" * 80)

    # Track statistics
    processed_count = 0
    start_time = time.time()

    # Store results by decision point
    all_decisions = {}
    frame_data = []
    ocr_calls_saved = 0
    total_possible_ocr = 0

    # Process frames
    for frame_info in frames_to_process:
        target_frame = frame_info["frame_num"]
        frame_time = frame_info["time"]
        target_elements = frame_info["elements"]
        frame_type = frame_info["type"]

        # Seek to target frame
        cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
        ret, frame = cap.read()

        if not ret:
            print(f"‚ùå Could not read frame {target_frame}")
            continue

        processed_count += 1

        try:
            # Analyze frame with selective OCR
            analysis_result = smart_analyzer.analyze_frame_smart(frame, frame_time, target_elements)

            # Track OCR efficiency
            total_possible_ocr += 4  # Could OCR all 4 elements
            ocr_calls_saved += 4 - len(target_elements)  # Saved by selective OCR

            # Group results by decision point
            decision_point = frame_info["decision_point"]
            if decision_point not in all_decisions:
                all_decisions[decision_point] = {
                    "frequent_results": [],
                    "rare_results": [],
                    "decision_time": decision_point,
                }

            # Add to appropriate category
            if any(elem in smart_analyzer.frequent_elements for elem in target_elements):
                all_decisions[decision_point]["frequent_results"].append(analysis_result)
            if any(elem in smart_analyzer.rare_elements for elem in target_elements):
                all_decisions[decision_point]["rare_results"].append(analysis_result)

            # Store frame data for screenshots
            if len(frame_data) < 12:  # Limit for speed
                frame_data.append(
                    {
                        "frame_num": target_frame,
                        "time": frame_time,
                        "frame": frame.copy(),
                        "decision_point": decision_point,
                        "analysis": analysis_result,
                        "frame_type": frame_type,
                        "target_elements": target_elements,
                    }
                )

            # Progress update
            if processed_count % 5 == 0:
                elapsed = time.time() - start_time
                progress = (processed_count / len(frames_to_process)) * 100
                fps_actual = processed_count / elapsed if elapsed > 0 else 0
                eta = (
                    (len(frames_to_process) - processed_count) / fps_actual if fps_actual > 0 else 0
                )

                print(
                    f"üß† {processed_count}/{len(frames_to_process)} frames ({progress:.1f}%) - "
                    f"{fps_actual:.1f} FPS - ETA: {eta:.0f}s"
                )

        except Exception as e:
            print(f"‚ùå Error frame {target_frame}: {e}")
            continue

    cap.release()

    # Process decisions with smart voting
    final_decisions = {}
    decision_quality = {"frequent": 0, "rare": 0, "total_frequent": 0, "total_rare": 0}

    print(f"\nüéØ PROCESSING SMART DECISIONS...")

    for decision_point, decision_data in all_decisions.items():
        frequent_results = decision_data["frequent_results"]
        rare_results = decision_data["rare_results"]

        decision_summary = {"time": decision_point, "values": {}}

        # Vote on frequent elements (clocks + down/distance)
        if frequent_results:
            for element_type in smart_analyzer.frequent_elements:
                vote_result = smart_analyzer.vote_on_smart_results(frequent_results, element_type)
                decision_summary["values"][element_type] = vote_result

                decision_quality["total_frequent"] += 1
                if vote_result["winner"] != "Unknown":
                    decision_quality["frequent"] += 1

        # Vote on rare elements (scores)
        if rare_results:
            for element_type in smart_analyzer.rare_elements:
                vote_result = smart_analyzer.vote_on_smart_results(rare_results, element_type)
                decision_summary["values"][element_type] = vote_result

                decision_quality["total_rare"] += 1
                if vote_result["winner"] != "Unknown":
                    decision_quality["rare"] += 1

        final_decisions[decision_point] = decision_summary

        # Show decision
        known_count = len(
            [v for v in decision_summary["values"].values() if v["winner"] != "Unknown"]
        )
        total_count = len(decision_summary["values"])
        print(f"‚è∞ {decision_point:.1f}s: {known_count}/{total_count} values decided")

    # Calculate final statistics
    processing_time = time.time() - start_time
    actual_fps = processed_count / processing_time if processing_time > 0 else 0
    speedup_factor = duration / processing_time if processing_time > 0 else 0
    ocr_efficiency = (ocr_calls_saved / total_possible_ocr) * 100 if total_possible_ocr > 0 else 0

    print(f"\nüß† SMART ANALYSIS COMPLETE!")
    print("=" * 80)
    print(f"üìä Video: {duration:.1f}s ({total_frames} total frames)")
    print(f"üìä Processed: {processed_count} frames ({len(final_decisions)} decisions)")
    print(f"‚è±Ô∏è  Processing time: {processing_time:.1f} seconds")
    print(f"üöÄ Processing speed: {actual_fps:.1f} FPS")
    print(f"‚ö° Real-time speedup: {speedup_factor:.1f}x")
    print(f"üí° OCR efficiency: {ocr_efficiency:.1f}% calls saved")

    # Performance assessment
    if processing_time < 12:
        print(f"üß† SMART SUCCESS: {processing_time:.1f}s (Target: 8-12s)")
    elif processing_time < 20:
        print(f"‚úÖ EXCELLENT: {processing_time:.1f}s (Under 20s)")
    else:
        print(f"‚ö†Ô∏è  NEEDS MORE: {processing_time:.1f}s (Still too slow)")

    # Show decision quality
    frequent_success = (
        (decision_quality["frequent"] / decision_quality["total_frequent"]) * 100
        if decision_quality["total_frequent"] > 0
        else 0
    )
    rare_success = (
        (decision_quality["rare"] / decision_quality["total_rare"]) * 100
        if decision_quality["total_rare"] > 0
        else 0
    )

    print(f"\nüéØ SMART DECISION QUALITY:")
    print("=" * 50)
    print(
        f'   üïê Frequent elements: {frequent_success:.1f}% success ({decision_quality["frequent"]}/{decision_quality["total_frequent"]})'
    )
    print(
        f'   üèÜ Rare elements: {rare_success:.1f}% success ({decision_quality["rare"]}/{decision_quality["total_rare"]})'
    )
    print(f"   üß† Smart decisions: {len(final_decisions)}")
    print(f"   ‚ö° Frames per decision: {processed_count / len(final_decisions):.1f}")

    # Show detailed results
    print(f"\nüìä DETAILED SMART RESULTS:")
    print("=" * 50)

    for decision_point in sorted(final_decisions.keys()):
        decision = final_decisions[decision_point]
        values = decision["values"]

        known_values = [k for k, v in values.items() if v["winner"] != "Unknown"]
        if known_values:
            print(f"‚è∞ {decision_point:.1f}s:")
            for element_type, vote_result in values.items():
                if vote_result["winner"] != "Unknown":
                    confidence = vote_result["confidence"] * 100
                    votes = vote_result["votes"]
                    total = vote_result["total"]
                    print(
                        f'   ‚úÖ {element_type}: {vote_result["winner"]} ({votes}/{total} votes, {confidence:.0f}%)'
                    )

    # Generate screenshots
    print(f"\nüì∏ GENERATING SCREENSHOTS...")
    print("=" * 50)

    num_screenshots = min(8, len(frame_data))
    if len(frame_data) <= num_screenshots:
        selected_frames = frame_data
    else:
        selected_frames = random.sample(frame_data, num_screenshots)
        selected_frames.sort(key=lambda x: x["frame_num"])

    for i, frame_info in enumerate(selected_frames, 1):
        frame_num = frame_info["frame_num"]
        frame_time = frame_info["time"]
        frame = frame_info["frame"]
        decision_point = frame_info["decision_point"]
        analysis = frame_info["analysis"]
        frame_type = frame_info["frame_type"]
        target_elements = frame_info["target_elements"]

        # Create annotated screenshot
        annotated_frame = frame.copy()

        # Add overlay
        overlay = annotated_frame.copy()
        cv2.rectangle(overlay, (5, 5), (475, 140), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.8, annotated_frame, 0.2, 0, annotated_frame)

        # Add text annotations
        y_pos = 20
        cv2.putText(
            annotated_frame,
            f"SMART - Frame #{frame_num} at {frame_time:.1f}s",
            (10, y_pos),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (0, 255, 0),
            1,
        )
        y_pos += 20

        cv2.putText(
            annotated_frame,
            f"Type: {frame_type} | Decision: {decision_point:.1f}s",
            (10, y_pos),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.3,
            (255, 255, 255),
            1,
        )
        y_pos += 15

        cv2.putText(
            annotated_frame,
            f'Target: {", ".join(target_elements)}',
            (10, y_pos),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.3,
            (255, 255, 0),
            1,
        )
        y_pos += 15

        # Add extracted values
        values = analysis["values"]
        known_vals = len([v for v in values.values() if v != "Unknown"])
        cv2.putText(
            annotated_frame,
            f"Extracted: {known_vals}/{len(target_elements)}",
            (10, y_pos),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.3,
            (0, 255, 255),
            1,
        )
        y_pos += 15

        # Add values
        for key, value in values.items():
            if value != "Unknown":
                color = (0, 255, 0)
                cv2.putText(
                    annotated_frame,
                    f"{key}: {value}",
                    (10, y_pos),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.3,
                    color,
                    1,
                )
                y_pos += 12

        # Save screenshot
        screenshot_path = output_dir / f"smart_{frame_num:04d}_{frame_time:.1f}s_{frame_type}.png"
        cv2.imwrite(str(screenshot_path), annotated_frame)

        if i <= 3:
            print(
                f"üìã Frame {i}: #{frame_num} ({frame_time:.1f}s) - {frame_type} - {len(target_elements)} elements"
            )

    print(f"üíæ {len(selected_frames)} screenshots saved to {output_dir}")

    print(f"\nüß† SMART INTERVALS TEST COMPLETE!")
    print("=" * 80)
    print(f"‚úÖ {duration:.1f}s video ‚Üí {processing_time:.1f}s analysis")
    print(f"‚úÖ {speedup_factor:.1f}x real-time processing")
    print(f"‚úÖ {ocr_efficiency:.1f}% OCR calls saved")
    print(f"‚úÖ {frequent_success:.1f}% frequent element success")
    print(f"‚úÖ {rare_success:.1f}% rare element success")
    print(f"‚úÖ {len(final_decisions)} smart decisions made")

    # Final assessment
    print(f"\nüìä SMART INTERVAL RESULTS:")
    if processing_time < 12:
        print(f"  üß† TARGET ACHIEVED: {processing_time:.1f}s (Goal: 8-12s)")
        print(f"  üöÄ Ready for production deployment")
    elif processing_time < 20:
        print(f"  ‚úÖ EXCELLENT: {processing_time:.1f}s (Under 20s)")
        print(f"  ‚úÖ Suitable for real-world use")
    else:
        print(f"  ‚ö†Ô∏è  MORE OPTIMIZATION NEEDED: {processing_time:.1f}s")

    print(f"  üéØ Multi-frequency efficiency: {ocr_efficiency:.1f}% OCR reduction")
    print(f"  üß† Smart sampling: {processed_count} frames ‚Üí {len(final_decisions)} decisions")
    print(f"  ‚ö° Frame efficiency: {processed_count / total_frames * 100:.3f}% of total frames")


if __name__ == "__main__":
    test_temporal_SMART_INTERVALS()
