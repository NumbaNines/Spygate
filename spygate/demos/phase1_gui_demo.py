#!/usr/bin/env python3

"""
Phase 1 Complete GUI Demo: Situational Analysis MVP
=================================================

This demo showcases the complete Phase 1 user experience with all GUI components
working together:

‚úÖ Video Import Feature - Drag-and-drop video upload with player identification
‚úÖ VideoTimeline Component - Playback controls with annotation display
‚úÖ HUD Analysis Pipeline - Real-time situation detection and OCR processing
‚úÖ Clip Organization - Smart tagging and filtering system
‚úÖ Situational Analysis - 3rd & Long, Red Zone, Two-minute warning detection
‚úÖ Performance Analytics - Hardware-optimized processing

Phase 1 MVP Deliverables:
- High-accuracy HUD Analysis Pipeline (OpenCV + YOLOv8)
- Core application infrastructure: video import, timeline UI, clip bookmarking
- Situational Gameplan Builder with strategy organization
- Manual annotation tools for building the Genesis Database
"""

import logging
import os
import sqlite3
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import cv2
import numpy as np
from PyQt6.QtCore import QSize, Qt, QThread, QTimer, pyqtSignal
from PyQt6.QtGui import QColor, QFont, QIcon, QPalette, QPixmap
from PyQt6.QtWidgets import (
    QApplication,
    QCheckBox,
    QComboBox,
    QDialog,
    QDialogButtonBox,
    QFileDialog,
    QFrame,
    QGridLayout,
    QGroupBox,
    QHBoxLayout,
    QHeaderView,
    QLabel,
    QLineEdit,
    QListWidget,
    QListWidgetItem,
    QMainWindow,
    QMessageBox,
    QProgressBar,
    QPushButton,
    QScrollArea,
    QSlider,
    QSpinBox,
    QSplitter,
    QTableWidget,
    QTableWidgetItem,
    QTabWidget,
    QTextEdit,
    QVBoxLayout,
    QWidget,
)

# Add the spygate package to the path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from spygate.core.hardware import HardwareDetector
    from spygate.ml.hud_detector import HUDDetector
    from spygate.ml.situation_detector import SituationDetector

    SPYGATE_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è  SpygateAI modules not available: {e}")
    SPYGATE_AVAILABLE = False

# Set up logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class VideoImportWidget(QWidget):
    """Video import interface with drag-and-drop support."""

    video_imported = pyqtSignal(str, dict)  # video_path, metadata

    def __init__(self):
        super().__init__()
        self.setup_ui()

    def setup_ui(self):
        layout = QVBoxLayout()

        # Title
        title = QLabel("üìπ Video Import - Phase 1 MVP")
        title.setFont(QFont("Arial", 16, QFont.Weight.Bold))
        title.setAlignment(Qt.AlignmentFlag.AlignCenter)
        layout.addWidget(title)

        # Import area
        self.import_frame = QFrame()
        self.import_frame.setStyleSheet(
            """
            QFrame {
                border: 2px dashed #3B82F6;
                border-radius: 10px;
                background-color: #F8FAFC;
                min-height: 200px;
            }
            QFrame:hover {
                background-color: #EFF6FF;
            }
        """
        )

        import_layout = QVBoxLayout()

        # Drag-drop label
        self.drop_label = QLabel(
            "üéÆ Drag & Drop Gameplay Videos Here\n\nSupported: MP4, MOV, AVI\nMax Size: 500MB"
        )
        self.drop_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.drop_label.setFont(QFont("Arial", 12))
        import_layout.addWidget(self.drop_label)

        # Browse button
        self.browse_btn = QPushButton("üìÅ Browse for Video")
        self.browse_btn.setStyleSheet(
            """
            QPushButton {
                background-color: #3B82F6;
                color: white;
                border: none;
                padding: 10px 20px;
                border-radius: 5px;
                font-size: 14px;
            }
            QPushButton:hover {
                background-color: #2563EB;
            }
        """
        )
        self.browse_btn.clicked.connect(self.browse_video)
        import_layout.addWidget(self.browse_btn, alignment=Qt.AlignmentFlag.AlignCenter)

        self.import_frame.setLayout(import_layout)
        layout.addWidget(self.import_frame)

        # Player identification
        player_group = QGroupBox("üë§ Player Identification")
        player_layout = QHBoxLayout()

        self.player_combo = QComboBox()
        self.player_combo.addItems(
            ["üéÆ My Gameplay", "üëÅÔ∏è Studying Opponent", "üìö Learning from Pros", "üîß Custom..."]
        )
        player_layout.addWidget(QLabel("Video Type:"))
        player_layout.addWidget(self.player_combo)

        self.player_name = QLineEdit()
        self.player_name.setPlaceholderText("Enter player/opponent name...")
        player_layout.addWidget(QLabel("Player:"))
        player_layout.addWidget(self.player_name)

        player_group.setLayout(player_layout)
        layout.addWidget(player_group)

        # Progress bar
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        layout.addWidget(self.progress_bar)

        # Status label
        self.status_label = QLabel("Ready to import videos")
        self.status_label.setStyleSheet("color: #059669; font-weight: bold;")
        layout.addWidget(self.status_label)

        self.setLayout(layout)

        # Enable drag and drop
        self.setAcceptDrops(True)

    def browse_video(self):
        """Open file browser for video selection."""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Gameplay Video", "", "Video Files (*.mp4 *.mov *.avi);;All Files (*)"
        )

        if file_path:
            self.import_video(file_path)

    def dragEnterEvent(self, event):
        """Handle drag enter event."""
        if event.mimeData().hasUrls():
            event.accept()
        else:
            event.ignore()

    def dropEvent(self, event):
        """Handle drop event."""
        files = [u.toLocalFile() for u in event.mimeData().urls()]
        if files:
            video_file = files[0]
            if video_file.lower().endswith((".mp4", ".mov", ".avi")):
                self.import_video(video_file)
            else:
                QMessageBox.warning(
                    self, "Invalid File", "Please select a valid video file (MP4, MOV, AVI)"
                )

    def import_video(self, file_path: str):
        """Import a video file."""
        try:
            self.status_label.setText("Importing video...")
            self.progress_bar.setVisible(True)
            self.progress_bar.setValue(0)

            # Simulate import progress
            for i in range(101):
                self.progress_bar.setValue(i)
                QApplication.processEvents()

            # Extract metadata
            cap = cv2.VideoCapture(file_path)
            metadata = {
                "duration": cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS),
                "fps": cap.get(cv2.CAP_PROP_FPS),
                "width": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
                "height": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
                "player_type": self.player_combo.currentText(),
                "player_name": self.player_name.text() or "Unknown",
                "import_date": datetime.now().isoformat(),
                "file_size": os.path.getsize(file_path),
            }
            cap.release()

            self.progress_bar.setVisible(False)
            self.status_label.setText(f"‚úÖ Successfully imported: {os.path.basename(file_path)}")

            # Emit signal
            self.video_imported.emit(file_path, metadata)

        except Exception as e:
            self.progress_bar.setVisible(False)
            self.status_label.setText(f"‚ùå Import failed: {str(e)}")
            QMessageBox.critical(self, "Import Error", f"Failed to import video:\n{str(e)}")


class VideoTimelineWidget(QWidget):
    """Video timeline with playback controls and annotation display."""

    def __init__(self):
        super().__init__()
        self.current_video = None
        self.cap = None
        self.total_frames = 0
        self.current_frame = 0
        self.annotations = []
        self.setup_ui()

    def setup_ui(self):
        layout = QVBoxLayout()

        # Title
        title = QLabel("üé¨ Video Timeline - Real-time Analysis")
        title.setFont(QFont("Arial", 16, QFont.Weight.Bold))
        layout.addWidget(title)

        # Video display
        self.video_label = QLabel("No video loaded")
        self.video_label.setStyleSheet(
            """
            QLabel {
                border: 1px solid #D1D5DB;
                background-color: #000000;
                color: white;
                text-align: center;
                min-height: 300px;
            }
        """
        )
        self.video_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.video_label.setScaledContents(True)
        layout.addWidget(self.video_label)

        # Timeline controls
        controls_layout = QHBoxLayout()

        # Play/Pause button
        self.play_btn = QPushButton("‚ñ∂Ô∏è Play")
        self.play_btn.clicked.connect(self.toggle_playback)
        controls_layout.addWidget(self.play_btn)

        # Timeline slider
        self.timeline_slider = QSlider(Qt.Orientation.Horizontal)
        self.timeline_slider.valueChanged.connect(self.seek_frame)
        controls_layout.addWidget(self.timeline_slider)

        # Frame info
        self.frame_info = QLabel("Frame: 0/0")
        controls_layout.addWidget(self.frame_info)

        layout.addWidget(QWidget())  # Add controls as a widget
        controls_widget = QWidget()
        controls_widget.setLayout(controls_layout)
        layout.addWidget(controls_widget)

        # Annotations display
        annotations_group = QGroupBox("üè∑Ô∏è Detected Situations")
        annotations_layout = QVBoxLayout()

        self.annotations_list = QListWidget()
        self.annotations_list.setMaximumHeight(150)
        annotations_layout.addWidget(self.annotations_list)

        annotations_group.setLayout(annotations_layout)
        layout.addWidget(annotations_group)

        self.setLayout(layout)

        # Timer for playback
        self.timer = QTimer()
        self.timer.timeout.connect(self.next_frame)
        self.is_playing = False

    def load_video(self, video_path: str):
        """Load a video for playback."""
        try:
            if self.cap:
                self.cap.release()

            self.cap = cv2.VideoCapture(video_path)
            self.current_video = video_path
            self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
            self.current_frame = 0

            self.timeline_slider.setMaximum(self.total_frames - 1)
            self.timeline_slider.setValue(0)

            # Load first frame
            self.seek_frame(0)

            # Clear annotations
            self.annotations_list.clear()
            self.annotations = []

        except Exception as e:
            QMessageBox.critical(self, "Video Error", f"Failed to load video:\n{str(e)}")

    def toggle_playback(self):
        """Toggle play/pause."""
        if not self.cap:
            return

        if self.is_playing:
            self.timer.stop()
            self.play_btn.setText("‚ñ∂Ô∏è Play")
            self.is_playing = False
        else:
            self.timer.start(33)  # ~30 FPS
            self.play_btn.setText("‚è∏Ô∏è Pause")
            self.is_playing = True

    def next_frame(self):
        """Advance to next frame."""
        if self.current_frame < self.total_frames - 1:
            self.seek_frame(self.current_frame + 1)
        else:
            self.toggle_playback()  # Stop at end

    def seek_frame(self, frame_num: int):
        """Seek to specific frame."""
        if not self.cap:
            return

        self.current_frame = frame_num
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)

        ret, frame = self.cap.read()
        if ret:
            # Convert to Qt format and display
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            h, w, ch = rgb_frame.shape
            bytes_per_line = ch * w
            qt_image = QPixmap.fromImage(
                QApplication.instance().imageFromData(
                    rgb_frame.tobytes(), w, h, bytes_per_line, "RGB888"
                )
            )

            # Scale to fit
            scaled_pixmap = qt_image.scaled(
                self.video_label.size(),
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation,
            )
            self.video_label.setPixmap(scaled_pixmap)

        self.timeline_slider.setValue(frame_num)
        self.frame_info.setText(f"Frame: {frame_num}/{self.total_frames}")

    def add_annotation(self, frame_num: int, annotation: dict[str, Any]):
        """Add an annotation to the timeline."""
        self.annotations.append({"frame": frame_num, "annotation": annotation})

        # Add to list widget
        item_text = f"Frame {frame_num}: {annotation.get('type', 'Unknown')} ({annotation.get('confidence', 0):.2f})"
        self.annotations_list.addItem(item_text)


class ClipOrganizationWidget(QWidget):
    """Clips organization with filtering and tagging."""

    def __init__(self):
        super().__init__()
        self.clips = []
        self.setup_ui()

    def setup_ui(self):
        layout = QVBoxLayout()

        # Title and controls
        header_layout = QHBoxLayout()

        title = QLabel("üìÇ Clip Organization - Smart Analysis")
        title.setFont(QFont("Arial", 16, QFont.Weight.Bold))
        header_layout.addWidget(title)

        header_layout.addStretch()

        # Search and filter
        self.search_box = QLineEdit()
        self.search_box.setPlaceholderText("üîç Search clips...")
        self.search_box.textChanged.connect(self.filter_clips)
        header_layout.addWidget(self.search_box)

        self.filter_combo = QComboBox()
        self.filter_combo.addItems(
            [
                "All Clips",
                "3rd & Long",
                "3rd & Short",
                "4th Down",
                "Red Zone",
                "Two-Minute Warning",
                "Close Game",
            ]
        )
        self.filter_combo.currentTextChanged.connect(self.filter_clips)
        header_layout.addWidget(self.filter_combo)

        layout.addLayout(header_layout)

        # Clips table
        self.clips_table = QTableWidget()
        self.clips_table.setColumnCount(7)
        self.clips_table.setHorizontalHeaderLabels(
            ["Video", "Player", "Situation", "Confidence", "Duration", "Date", "Actions"]
        )

        # Make table responsive
        header = self.clips_table.horizontalHeader()
        header.setSectionResizeMode(0, QHeaderView.ResizeMode.Stretch)
        header.setSectionResizeMode(1, QHeaderView.ResizeMode.ResizeToContents)
        header.setSectionResizeMode(2, QHeaderView.ResizeMode.ResizeToContents)
        header.setSectionResizeMode(3, QHeaderView.ResizeMode.ResizeToContents)
        header.setSectionResizeMode(4, QHeaderView.ResizeMode.ResizeToContents)
        header.setSectionResizeMode(5, QHeaderView.ResizeMode.ResizeToContents)
        header.setSectionResizeMode(6, QHeaderView.ResizeMode.ResizeToContents)

        layout.addWidget(self.clips_table)

        # Stats summary
        self.stats_label = QLabel("üìä Total clips: 0 | Analyzed situations: 0")
        self.stats_label.setStyleSheet("color: #6B7280; font-style: italic;")
        layout.addWidget(self.stats_label)

        self.setLayout(layout)

    def add_clip(self, video_path: str, metadata: dict[str, Any], situations: list[dict[str, Any]]):
        """Add a clip to the organization system."""
        clip_data = {
            "video_path": video_path,
            "metadata": metadata,
            "situations": situations,
            "filename": os.path.basename(video_path),
        }

        self.clips.append(clip_data)
        self.refresh_table()

    def refresh_table(self):
        """Refresh the clips table."""
        self.clips_table.setRowCount(len(self.clips))

        for row, clip in enumerate(self.clips):
            # Video name
            self.clips_table.setItem(row, 0, QTableWidgetItem(clip["filename"]))

            # Player
            player = clip["metadata"].get("player_name", "Unknown")
            self.clips_table.setItem(row, 1, QTableWidgetItem(player))

            # Situations
            situations = clip["situations"]
            if situations:
                situation_text = f"{len(situations)} situations"
                confidence = sum(s.get("confidence", 0) for s in situations) / len(situations)
            else:
                situation_text = "No situations"
                confidence = 0

            self.clips_table.setItem(row, 2, QTableWidgetItem(situation_text))
            self.clips_table.setItem(row, 3, QTableWidgetItem(f"{confidence:.2f}"))

            # Duration
            duration = clip["metadata"].get("duration", 0)
            duration_text = f"{duration:.1f}s"
            self.clips_table.setItem(row, 4, QTableWidgetItem(duration_text))

            # Date
            date = clip["metadata"].get("import_date", "Unknown")
            if date != "Unknown":
                try:
                    dt = datetime.fromisoformat(date)
                    date_text = dt.strftime("%Y-%m-%d %H:%M")
                except:
                    date_text = date
            else:
                date_text = date
            self.clips_table.setItem(row, 5, QTableWidgetItem(date_text))

            # Actions
            self.clips_table.setItem(row, 6, QTableWidgetItem("üìä Analyze"))

        # Update stats
        total_situations = sum(len(clip["situations"]) for clip in self.clips)
        self.stats_label.setText(
            f"üìä Total clips: {len(self.clips)} | Analyzed situations: {total_situations}"
        )

    def filter_clips(self):
        """Filter clips based on search and filter criteria."""
        search_text = self.search_box.text().lower()
        filter_type = self.filter_combo.currentText()

        for row in range(self.clips_table.rowCount()):
            show_row = True

            # Search filter
            if search_text:
                row_text = ""
                for col in range(self.clips_table.columnCount() - 1):  # Exclude actions column
                    item = self.clips_table.item(row, col)
                    if item:
                        row_text += item.text().lower() + " "

                if search_text not in row_text:
                    show_row = False

            # Type filter
            if filter_type != "All Clips" and show_row:
                clip = self.clips[row] if row < len(self.clips) else None
                if clip:
                    situation_types = [s.get("type", "") for s in clip["situations"]]
                    filter_mapping = {
                        "3rd & Long": "3rd_and_long",
                        "3rd & Short": "3rd_and_short",
                        "4th Down": "4th_down",
                        "Red Zone": "red_zone",
                        "Two-Minute Warning": "two_minute_warning",
                        "Close Game": "close_game",
                    }

                    if filter_mapping.get(filter_type) not in situation_types:
                        show_row = False

            self.clips_table.setRowHidden(row, not show_row)


class AnalysisWorker(QThread):
    """Background worker for video analysis."""

    analysis_complete = pyqtSignal(dict)  # Analysis results
    progress_update = pyqtSignal(int)  # Progress percentage

    def __init__(self, video_path: str):
        super().__init__()
        self.video_path = video_path

    def run(self):
        """Run analysis in background."""
        try:
            if not SPYGATE_AVAILABLE:
                # Mock analysis for demo
                self.progress_update.emit(50)
                self.msleep(1000)  # Simulate processing

                mock_result = {
                    "situations": [
                        {
                            "type": "3rd_and_long",
                            "confidence": 0.89,
                            "frame_number": 145,
                            "timestamp": 4.8,
                            "details": {
                                "down": 3,
                                "distance": 8,
                                "yard_line": "OPP 25",
                                "source": "hud_analysis",
                            },
                        },
                        {
                            "type": "red_zone",
                            "confidence": 0.85,
                            "frame_number": 145,
                            "timestamp": 4.8,
                            "details": {
                                "yard_line": "OPP 25",
                                "yards_to_goal": 25,
                                "source": "hud_analysis",
                            },
                        },
                    ],
                    "hud_info": {
                        "down": 3,
                        "distance": 8,
                        "yard_line": "OPP 25",
                        "score_home": 14,
                        "score_away": 21,
                        "game_clock": "2:15",
                        "confidence": 0.85,
                    },
                }

                self.progress_update.emit(100)
                self.analysis_complete.emit(mock_result)
                return

            # Real analysis
            self.progress_update.emit(20)

            # Initialize detector
            hardware = HardwareDetector()
            situation_detector = SituationDetector()

            self.progress_update.emit(40)

            # Analyze key frames
            cap = cv2.VideoCapture(self.video_path)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)

            situations = []
            hud_info = {}

            # Sample every 30 frames for analysis
            for frame_num in range(0, min(total_frames, 300), 30):
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
                ret, frame = cap.read()

                if ret:
                    timestamp = frame_num / fps
                    result = situation_detector.analyze_frame(frame, frame_num, timestamp)

                    if result:
                        situations.extend(result.get("situations", []))
                        if not hud_info and result.get("hud_info"):
                            hud_info = result["hud_info"]

                progress = 40 + int((frame_num / min(total_frames, 300)) * 50)
                self.progress_update.emit(progress)

            cap.release()

            self.progress_update.emit(100)
            self.analysis_complete.emit({"situations": situations, "hud_info": hud_info})

        except Exception as e:
            logger.error(f"Analysis failed: {e}")
            self.analysis_complete.emit({"error": str(e)})


class Phase1MainWindow(QMainWindow):
    """Main application window for Phase 1 GUI demo."""

    def __init__(self):
        super().__init__()
        self.current_video = None
        self.setup_ui()
        self.setup_hardware_info()

    def setup_ui(self):
        """Set up the main UI."""
        self.setWindowTitle("SpygateAI - Phase 1 Complete GUI Demo")
        self.setGeometry(100, 100, 1400, 900)

        # Set application style
        self.setStyleSheet(
            """
            QMainWindow {
                background-color: #F9FAFB;
            }
            QTabWidget::pane {
                border: 1px solid #D1D5DB;
                background-color: white;
            }
            QTabBar::tab {
                background-color: #F3F4F6;
                padding: 8px 16px;
                margin-right: 2px;
            }
            QTabBar::tab:selected {
                background-color: #3B82F6;
                color: white;
            }
        """
        )

        # Central widget with tabs
        central_widget = QWidget()
        self.setCentralWidget(central_widget)

        layout = QVBoxLayout()

        # Header
        header = QLabel("üèà SpygateAI - Phase 1 Complete Demo")
        header.setFont(QFont("Arial", 20, QFont.Weight.Bold))
        header.setAlignment(Qt.AlignmentFlag.AlignCenter)
        header.setStyleSheet(
            """
            QLabel {
                color: #1F2937;
                padding: 20px;
                background-color: #EFF6FF;
                border-bottom: 3px solid #3B82F6;
            }
        """
        )
        layout.addWidget(header)

        # Tab widget
        self.tab_widget = QTabWidget()

        # Import tab
        self.import_widget = VideoImportWidget()
        self.import_widget.video_imported.connect(self.on_video_imported)
        self.tab_widget.addTab(self.import_widget, "üìπ Import")

        # Timeline tab
        self.timeline_widget = VideoTimelineWidget()
        self.tab_widget.addTab(self.timeline_widget, "üé¨ Timeline")

        # Clips tab
        self.clips_widget = ClipOrganizationWidget()
        self.tab_widget.addTab(self.clips_widget, "üìÇ Clips")

        # Analysis tab
        self.analysis_widget = self.create_analysis_widget()
        self.tab_widget.addTab(self.analysis_widget, "üìä Analysis")

        layout.addWidget(self.tab_widget)

        # Status bar
        self.status_bar = self.statusBar()
        self.status_bar.showMessage("Ready - Phase 1 Situational Analysis MVP")

        central_widget.setLayout(layout)

    def create_analysis_widget(self):
        """Create the analysis results widget."""
        widget = QWidget()
        layout = QVBoxLayout()

        # Title
        title = QLabel("üìä Real-time Situation Analysis")
        title.setFont(QFont("Arial", 16, QFont.Weight.Bold))
        layout.addWidget(title)

        # Analysis controls
        controls_group = QGroupBox("üîß Analysis Controls")
        controls_layout = QHBoxLayout()

        self.analyze_btn = QPushButton("üöÄ Analyze Current Video")
        self.analyze_btn.setStyleSheet(
            """
            QPushButton {
                background-color: #059669;
                color: white;
                border: none;
                padding: 10px 20px;
                border-radius: 5px;
                font-size: 14px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #047857;
            }
            QPushButton:disabled {
                background-color: #D1D5DB;
                color: #6B7280;
            }
        """
        )
        self.analyze_btn.clicked.connect(self.start_analysis)
        self.analyze_btn.setEnabled(False)
        controls_layout.addWidget(self.analyze_btn)

        controls_layout.addStretch()

        # Progress
        self.analysis_progress = QProgressBar()
        self.analysis_progress.setVisible(False)
        controls_layout.addWidget(self.analysis_progress)

        controls_group.setLayout(controls_layout)
        layout.addWidget(controls_group)

        # Results
        results_group = QGroupBox("üéØ Analysis Results")
        results_layout = QVBoxLayout()

        self.results_text = QTextEdit()
        self.results_text.setReadOnly(True)
        self.results_text.setMaximumHeight(300)
        results_layout.addWidget(self.results_text)

        results_group.setLayout(results_layout)
        layout.addWidget(results_group)

        # Hardware info
        self.hardware_info = QTextEdit()
        self.hardware_info.setReadOnly(True)
        self.hardware_info.setMaximumHeight(150)
        layout.addWidget(self.hardware_info)

        widget.setLayout(layout)
        return widget

    def setup_hardware_info(self):
        """Display hardware information."""
        try:
            if SPYGATE_AVAILABLE:
                hardware = HardwareDetector()
                hardware.initialize()

                info_text = f"""
üñ•Ô∏è Hardware Configuration:
   ‚Ä¢ Tier: {hardware.tier.name}
   ‚Ä¢ CPU Cores: {hardware.cpu_cores}
   ‚Ä¢ RAM: {hardware.ram_gb:.1f} GB
   ‚Ä¢ GPU Available: {'‚úÖ' if hardware.has_cuda else '‚ùå'}
   ‚Ä¢ GPU Memory: {hardware.gpu_memory_gb:.1f} GB

‚ö° Phase 1 Optimizations:
   ‚Ä¢ YOLOv8 Model: Optimized for {hardware.tier.name} tier
   ‚Ä¢ Processing Speed: {hardware.tier.value}x performance scaling
   ‚Ä¢ OCR Engine: {'EasyOCR + Tesseract' if hardware.has_cuda else 'Tesseract only'}
   ‚Ä¢ Real-time Analysis: {'Enabled' if hardware.tier.value >= 3 else 'Basic mode'}
"""
            else:
                info_text = """
üñ•Ô∏è Hardware Configuration: Demo Mode
   ‚Ä¢ SpygateAI modules not available
   ‚Ä¢ Running in simulation mode
   ‚Ä¢ All features demonstrated with mock data
"""

            self.hardware_info.setText(info_text)

        except Exception as e:
            self.hardware_info.setText(f"Hardware detection error: {e}")

    def on_video_imported(self, video_path: str, metadata: dict[str, Any]):
        """Handle video import."""
        self.current_video = video_path

        # Load video in timeline
        self.timeline_widget.load_video(video_path)

        # Enable analysis
        self.analyze_btn.setEnabled(True)

        # Switch to timeline tab
        self.tab_widget.setCurrentIndex(1)

        # Update status
        self.status_bar.showMessage(f"Video loaded: {os.path.basename(video_path)}")

        # Show success message
        QMessageBox.information(
            self,
            "Video Imported",
            f"Successfully imported:\n{os.path.basename(video_path)}\n\nDuration: {metadata['duration']:.1f}s\nResolution: {metadata['width']}x{metadata['height']}\nPlayer: {metadata['player_name']}",
        )

    def start_analysis(self):
        """Start video analysis."""
        if not self.current_video:
            return

        self.analyze_btn.setEnabled(False)
        self.analysis_progress.setVisible(True)
        self.analysis_progress.setValue(0)

        # Clear previous results
        self.results_text.clear()
        self.results_text.append("üöÄ Starting Phase 1 Situational Analysis...\n")

        # Start analysis worker
        self.analysis_worker = AnalysisWorker(self.current_video)
        self.analysis_worker.progress_update.connect(self.update_analysis_progress)
        self.analysis_worker.analysis_complete.connect(self.on_analysis_complete)
        self.analysis_worker.start()

    def update_analysis_progress(self, progress: int):
        """Update analysis progress."""
        self.analysis_progress.setValue(progress)

        if progress == 20:
            self.results_text.append("üîß Initializing hardware-optimized YOLOv8 detector...")
        elif progress == 40:
            self.results_text.append("üéØ Beginning HUD element detection...")
        elif progress == 60:
            self.results_text.append("üìù Processing OCR for game state extraction...")
        elif progress == 80:
            self.results_text.append("üß† Analyzing situational patterns...")

    def on_analysis_complete(self, results: dict[str, Any]):
        """Handle analysis completion."""
        self.analysis_progress.setVisible(False)
        self.analyze_btn.setEnabled(True)

        if "error" in results:
            self.results_text.append(f"‚ùå Analysis failed: {results['error']}")
            return

        # Display results
        self.results_text.append("‚úÖ Analysis Complete!\n")

        # HUD Information
        hud_info = results.get("hud_info", {})
        if hud_info:
            self.results_text.append("üéØ Detected HUD Information:")
            for key, value in hud_info.items():
                if value is not None and key != "raw_detections":
                    self.results_text.append(f"   ‚Ä¢ {key}: {value}")
            self.results_text.append("")

        # Situations
        situations = results.get("situations", [])
        if situations:
            self.results_text.append(f"üö® Detected Situations ({len(situations)}):")
            for situation in situations:
                confidence = situation.get("confidence", 0)
                situation_type = situation.get("type", "Unknown")
                self.results_text.append(f"   ‚Ä¢ {situation_type} (confidence: {confidence:.2f})")

                # Add to timeline annotations
                frame_num = situation.get("frame_number", 0)
                self.timeline_widget.add_annotation(frame_num, situation)

            self.results_text.append("")
        else:
            self.results_text.append("‚ÑπÔ∏è No specific situations detected in this clip\n")

        # Add to clips organization
        metadata = {
            "player_name": "Demo Player",
            "duration": 30.0,
            "import_date": datetime.now().isoformat(),
        }

        self.clips_widget.add_clip(self.current_video, metadata, situations)

        # Performance summary
        self.results_text.append("üìà Performance Summary:")
        self.results_text.append(f"   ‚Ä¢ Processing completed in real-time")
        self.results_text.append(f"   ‚Ä¢ Situations analyzed: {len(situations)}")
        self.results_text.append(f"   ‚Ä¢ HUD confidence: {hud_info.get('confidence', 0):.2f}")
        self.results_text.append(f"   ‚Ä¢ Ready for next analysis!")

        # Update status
        self.status_bar.showMessage(f"Analysis complete: {len(situations)} situations detected")


def main():
    """Main application entry point."""
    app = QApplication(sys.argv)

    # Set application properties
    app.setApplicationName("SpygateAI Phase 1 Demo")
    app.setApplicationVersion("2.0.0-phase1")
    app.setOrganizationName("SpygateAI")

    # Show splash screen
    splash_msg = QMessageBox()
    splash_msg.setWindowTitle("SpygateAI Phase 1")
    splash_msg.setText(
        """
üèà SpygateAI Phase 1 Complete GUI Demo

‚úÖ Video Import Feature
‚úÖ VideoTimeline Component
‚úÖ HUD Analysis Pipeline
‚úÖ Clip Organization
‚úÖ Situational Analysis
‚úÖ Performance Analytics

Ready to transform your gameplay analysis!
    """
    )
    splash_msg.setStandardButtons(QMessageBox.StandardButton.Ok)
    splash_msg.exec()

    # Create and show main window
    window = Phase1MainWindow()
    window.show()

    return app.exec()


if __name__ == "__main__":
    sys.exit(main())
