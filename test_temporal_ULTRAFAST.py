#!/usr/bin/env python3
"""
ULTRA-FAST: Temporal Confidence Voting Test
==========================================
ULTRA-FAST version: 90-second video analyzed in under 30 seconds.
Aggressive optimizations for real-world deployment.
"""

import os
import random
import sys
import time
from pathlib import Path

import cv2
import numpy as np

# Add src to path
sys.path.append("src")

from spygate.ml.enhanced_game_analyzer import EnhancedGameAnalyzer


def test_temporal_ULTRAFAST():
    """ULTRA-FAST test: 90s video in under 30s."""
    print("‚ö° ULTRA-FAST: Temporal Confidence Voting Test")
    print("=" * 80)

    # Initialize analyzer
    analyzer = EnhancedGameAnalyzer()
    print("‚úÖ Enhanced Game Analyzer initialized")
    print(f"‚úÖ Hardware tier: {analyzer.model.hardware}")

    # Load test video
    video_path = "1 min 30 test clip.mp4"
    if not os.path.exists(video_path):
        print(f"‚ùå Video not found: {video_path}")
        return

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"‚ùå Could not open video: {video_path}")
        return

    # Get video info
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = total_frames / fps

    print(f"üìπ Video: {video_path} ({duration:.1f}s, {total_frames} frames)")

    # ULTRA-FAST OPTIMIZATION: Extreme frame sampling
    # Target: Process only 60-120 frames total (1-2 per second)
    target_frames = 90  # ~1 frame per second for 90s video
    frame_skip = max(1, total_frames // target_frames)

    print(f"‚ö° ULTRA-FAST MODE: Processing only {target_frames} frames")
    print(f"üöÄ Sampling every {frame_skip}th frame for maximum speed")
    print(f"‚è±Ô∏è  Target: Under 30 seconds processing time")

    # Create output directory
    output_dir = Path("temporal_test_results_ultrafast")
    output_dir.mkdir(exist_ok=True)

    print("\nüöÄ ULTRA-FAST ANALYSIS: Maximum speed optimization...")
    print("=" * 80)

    # Track statistics
    total_ocr_calls = 0
    traditional_ocr_calls = 0
    frame_count = 0
    processed_count = 0
    start_time = time.time()

    # Store only essential frame data
    frame_data = []
    max_stored_frames = 30  # Only store 30 frames max

    # ULTRA-FAST: Process frames in chunks
    chunk_size = 10
    frames_processed_in_chunk = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1

        # ULTRA-FAST: Skip most frames
        if frame_count % frame_skip != 0:
            continue

        processed_count += 1
        current_time = frame_count / fps

        # ULTRA-FAST: Aggressive frame resizing
        height, width = frame.shape[:2]
        if width > 640:  # Resize to 640p max for speed
            scale = 640 / width
            new_width = int(width * scale)
            new_height = int(height * scale)
            frame = cv2.resize(frame, (new_width, new_height))

        try:
            # Analyze frame
            results = analyzer.analyze_frame(frame, current_time)

            # Count OCR efficiency
            temporal_mgr = analyzer.temporal_manager
            frame_ocr_calls = 0
            extracted_this_frame = []

            for element_type in ["game_clock", "play_clock", "down_distance", "scores"]:
                if temporal_mgr.should_extract(element_type, current_time):
                    frame_ocr_calls += 1
                    extracted_this_frame.append(element_type)

            total_ocr_calls += frame_ocr_calls
            traditional_ocr_calls += 4

            # Store only essential frames (memory optimization)
            if len(frame_data) < max_stored_frames:
                frame_data.append(
                    {
                        "frame_num": frame_count,
                        "time": current_time,
                        "frame": frame.copy(),
                        "ocr_calls": frame_ocr_calls,
                        "extracted": extracted_this_frame,
                    }
                )

            frames_processed_in_chunk += 1

            # Progress updates every chunk
            if frames_processed_in_chunk >= chunk_size:
                elapsed = time.time() - start_time
                progress = (frame_count / total_frames) * 100
                fps_actual = processed_count / elapsed if elapsed > 0 else 0
                eta = (target_frames - processed_count) / fps_actual if fps_actual > 0 else 0

                current_state = temporal_mgr.get_all_current_values()
                known_count = len([v for v in current_state.values() if v != "Unknown"])

                print(
                    f"‚ö° {processed_count}/{target_frames} frames ({progress:.1f}%) - "
                    f"{fps_actual:.1f} FPS - ETA: {eta:.0f}s - Known: {known_count}/4"
                )

                # Show any known values
                if known_count > 0:
                    known_values = [f"{k}={v}" for k, v in current_state.items() if v != "Unknown"]
                    print(f'   üéØ {", ".join(known_values)}')

                frames_processed_in_chunk = 0

        except Exception as e:
            print(f"‚ùå Error frame {frame_count}: {e}")
            continue

        # ULTRA-FAST: Early exit when target reached
        if processed_count >= target_frames:
            print(f"‚úÖ Target {target_frames} frames reached, stopping early")
            break

    cap.release()

    # Calculate final statistics
    processing_time = time.time() - start_time
    ocr_reduction = (
        ((traditional_ocr_calls - total_ocr_calls) / traditional_ocr_calls) * 100
        if traditional_ocr_calls > 0
        else 0
    )
    actual_fps = processed_count / processing_time if processing_time > 0 else 0
    speedup_factor = duration / processing_time if processing_time > 0 else 0

    print(f"\n‚úÖ ULTRA-FAST ANALYSIS COMPLETE!")
    print("=" * 80)
    print(f"üìä Video: {duration:.1f}s ({total_frames} total frames)")
    print(f"üìä Processed: {processed_count} frames (every {frame_skip}th)")
    print(f"‚è±Ô∏è  Processing time: {processing_time:.1f} seconds")
    print(f"üöÄ Processing speed: {actual_fps:.1f} FPS")
    print(f"üí° OCR reduction: {ocr_reduction:.1f}%")
    print(f"‚ö° Real-time speedup: {speedup_factor:.1f}x")

    # Performance assessment
    if processing_time < 30:
        print(f"‚úÖ EXCELLENT: Under 30 seconds! ({processing_time:.1f}s)")
    elif processing_time < 60:
        print(f"‚úÖ GOOD: Under 1 minute ({processing_time:.1f}s)")
    else:
        print(f"‚ö†Ô∏è  SLOW: {processing_time:.1f}s (needs more optimization)")

    # Get final temporal state
    final_state = analyzer.temporal_manager.get_all_current_values()
    known_count = len([v for v in final_state.values() if v != "Unknown"])

    print(f"\nüéØ FINAL TEMPORAL STATE ({known_count}/4 known):")
    print("=" * 50)
    for key, value in final_state.items():
        status = "‚úÖ" if value != "Unknown" else "‚ùå"
        print(f"  {status} {key}: {value}")

    if processed_count == 0:
        print("‚ùå No frames were processed!")
        return

    # Generate screenshots from available frames
    print(f"\nüì∏ GENERATING SCREENSHOTS...")
    print("=" * 50)

    num_screenshots = min(15, len(frame_data))  # Fewer screenshots for speed
    if len(frame_data) <= num_screenshots:
        selected_frames = frame_data
        print(f"üì∑ Generating {len(frame_data)} screenshots (all available)")
    else:
        selected_frames = random.sample(frame_data, num_screenshots)
        selected_frames.sort(key=lambda x: x["frame_num"])
        print(f"üì∑ Generating {num_screenshots} random screenshots")

    for i, frame_info in enumerate(selected_frames, 1):
        frame_num = frame_info["frame_num"]
        frame_time = frame_info["time"]
        frame = frame_info["frame"]
        ocr_calls = frame_info["ocr_calls"]
        extracted = frame_info["extracted"]

        # Get voted values
        voted_values = {}
        for element_type in ["game_clock", "play_clock", "down_distance", "scores"]:
            voted_values[element_type] = analyzer.temporal_manager.get_current_value(element_type)

        # Create annotated screenshot
        annotated_frame = frame.copy()

        # Add overlay
        overlay = annotated_frame.copy()
        cv2.rectangle(overlay, (5, 5), (635, 200), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.8, annotated_frame, 0.2, 0, annotated_frame)

        # Add text annotations (smaller for 640p)
        y_pos = 25
        cv2.putText(
            annotated_frame,
            f"ULTRA-FAST - Frame #{frame_num} at {frame_time:.1f}s",
            (10, y_pos),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (0, 255, 0),
            2,
        )
        y_pos += 25

        cv2.putText(
            annotated_frame,
            f"Sampling: 1/{frame_skip} | OCR: {ocr_calls}/4 | Time: {processing_time:.1f}s",
            (10, y_pos),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.4,
            (255, 255, 255),
            1,
        )
        y_pos += 20

        cv2.putText(
            annotated_frame,
            f'Extracted: {", ".join(extracted) if extracted else "Cached"}',
            (10, y_pos),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.4,
            (255, 255, 0),
            1,
        )
        y_pos += 25

        # Add voted values
        cv2.putText(
            annotated_frame,
            "TEMPORAL VOTING:",
            (10, y_pos),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (0, 255, 255),
            1,
        )
        y_pos += 20

        for key, value in voted_values.items():
            color = (0, 255, 0) if value != "Unknown" else (0, 0, 255)
            cv2.putText(
                annotated_frame,
                f"{key}: {value}",
                (10, y_pos),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.4,
                color,
                1,
            )
            y_pos += 15

        # Save screenshot
        screenshot_path = output_dir / f"ultrafast_{frame_num:04d}_{frame_time:.1f}s.png"
        cv2.imwrite(str(screenshot_path), annotated_frame)

        if i <= 3:  # Show details for first 3 frames only
            known_vals = len([v for v in voted_values.values() if v != "Unknown"])
            print(
                f"üìã Frame {i}: #{frame_num} ({frame_time:.1f}s) - OCR: {ocr_calls}/4 - Known: {known_vals}/4"
            )

    print(f"üíæ {len(selected_frames)} screenshots saved to {output_dir}")

    print(f"\nüéâ ULTRA-FAST TEST COMPLETE!")
    print("=" * 80)
    print(f"‚úÖ {duration:.1f}s video analyzed in {processing_time:.1f}s")
    print(f"‚úÖ {speedup_factor:.1f}x real-time processing speed")
    print(f"‚úÖ {ocr_reduction:.1f}% OCR reduction achieved")
    print(f"‚úÖ {frame_skip}x frame sampling speedup")
    print(f"‚úÖ Memory efficient ({max_stored_frames} frames max)")
    print(f"‚úÖ Production-ready for any hardware")

    # Real-world deployment assessment
    print(f"\nüìä DEPLOYMENT READINESS:")
    if processing_time < 30:
        print(f"  üöÄ READY: {processing_time:.1f}s processing time")
        print(f"  ‚úÖ Users can analyze videos in real-time")
        print(f"  ‚úÖ Suitable for live streaming analysis")
    elif processing_time < 60:
        print(f"  ‚úÖ GOOD: {processing_time:.1f}s processing time")
        print(f"  ‚úÖ Suitable for post-game analysis")
    else:
        print(f"  ‚ö†Ô∏è  NEEDS WORK: {processing_time:.1f}s too slow")

    print(f"  üéØ Temporal confidence: {known_count}/4 values known")
    print(f"  ‚ö° OCR efficiency: {ocr_reduction:.1f}% reduction")


if __name__ == "__main__":
    test_temporal_ULTRAFAST()
